{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "Once you've chosen your scenario, download the data from [the Iowa website](https://data.iowa.gov/Economy/Iowa-Liquor-Sales/m3tr-qhgy) in csv format. Start by loading the data with pandas. You may need to parse the date columns appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:34.613431",
     "start_time": "2016-10-12T09:49:34.523588"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:34.622095",
     "start_time": "2016-10-12T09:49:34.617112"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Format how pandas returns floats\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:34.633674",
     "start_time": "2016-10-12T09:49:34.625979"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We decided to bring in external data so we'll be reading from three files\n",
    "# Write a function that loads the data and returns a dataframe\n",
    "def load_file(file_name):\n",
    "    file_path_name = base_path + file_name\n",
    "    try:\n",
    "        return pd.read_csv(file_path_name, low_memory=False)\n",
    "    except:\n",
    "        print 'Error: Check file path/ name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:34.657029",
     "start_time": "2016-10-12T09:49:34.637133"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define our base path\n",
    "base_path = 'C:/Users/Elizabeth/GA-DSI/projects/projects-weekly/project-03/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:35.899929",
     "start_time": "2016-10-12T09:49:34.659989"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Load the liquor sales data into a DataFrame\n",
    "df = load_file('Iowa_Liquor_sales_sample_10pct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:37.400155",
     "start_time": "2016-10-12T09:49:35.902047"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Transform the dates if needed, e.g.\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:37.693827",
     "start_time": "2016-10-12T09:49:37.403024"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store Number</th>\n",
       "      <th>City</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>County Number</th>\n",
       "      <th>County</th>\n",
       "      <th>Category</th>\n",
       "      <th>Category Name</th>\n",
       "      <th>Vendor Number</th>\n",
       "      <th>Item Number</th>\n",
       "      <th>Item Description</th>\n",
       "      <th>Bottle Volume (ml)</th>\n",
       "      <th>State Bottle Cost</th>\n",
       "      <th>State Bottle Retail</th>\n",
       "      <th>Bottles Sold</th>\n",
       "      <th>Sale (Dollars)</th>\n",
       "      <th>Volume Sold (Liters)</th>\n",
       "      <th>Volume Sold (Gallons)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>3717</td>\n",
       "      <td>SUMNER</td>\n",
       "      <td>50674</td>\n",
       "      <td>9.00</td>\n",
       "      <td>Bremer</td>\n",
       "      <td>1051100.00</td>\n",
       "      <td>APRICOT BRANDIES</td>\n",
       "      <td>55</td>\n",
       "      <td>54436</td>\n",
       "      <td>Mr. Boston Apricot Brandy</td>\n",
       "      <td>750</td>\n",
       "      <td>$4.50</td>\n",
       "      <td>$6.75</td>\n",
       "      <td>12</td>\n",
       "      <td>$81.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-02</td>\n",
       "      <td>2614</td>\n",
       "      <td>DAVENPORT</td>\n",
       "      <td>52807</td>\n",
       "      <td>82.00</td>\n",
       "      <td>Scott</td>\n",
       "      <td>1011100.00</td>\n",
       "      <td>BLENDED WHISKIES</td>\n",
       "      <td>395</td>\n",
       "      <td>27605</td>\n",
       "      <td>Tin Cup</td>\n",
       "      <td>750</td>\n",
       "      <td>$13.75</td>\n",
       "      <td>$20.63</td>\n",
       "      <td>2</td>\n",
       "      <td>$41.26</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-11</td>\n",
       "      <td>2106</td>\n",
       "      <td>CEDAR FALLS</td>\n",
       "      <td>50613</td>\n",
       "      <td>7.00</td>\n",
       "      <td>Black Hawk</td>\n",
       "      <td>1011200.00</td>\n",
       "      <td>STRAIGHT BOURBON WHISKIES</td>\n",
       "      <td>65</td>\n",
       "      <td>19067</td>\n",
       "      <td>Jim Beam</td>\n",
       "      <td>1000</td>\n",
       "      <td>$12.59</td>\n",
       "      <td>$18.89</td>\n",
       "      <td>24</td>\n",
       "      <td>$453.36</td>\n",
       "      <td>24.00</td>\n",
       "      <td>6.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-03</td>\n",
       "      <td>2501</td>\n",
       "      <td>AMES</td>\n",
       "      <td>50010</td>\n",
       "      <td>85.00</td>\n",
       "      <td>Story</td>\n",
       "      <td>1071100.00</td>\n",
       "      <td>AMERICAN COCKTAILS</td>\n",
       "      <td>395</td>\n",
       "      <td>59154</td>\n",
       "      <td>1800 Ultimate Margarita</td>\n",
       "      <td>1750</td>\n",
       "      <td>$9.50</td>\n",
       "      <td>$14.25</td>\n",
       "      <td>6</td>\n",
       "      <td>$85.50</td>\n",
       "      <td>10.50</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-08-18</td>\n",
       "      <td>3654</td>\n",
       "      <td>BELMOND</td>\n",
       "      <td>50421</td>\n",
       "      <td>99.00</td>\n",
       "      <td>Wright</td>\n",
       "      <td>1031080.00</td>\n",
       "      <td>VODKA 80 PROOF</td>\n",
       "      <td>297</td>\n",
       "      <td>35918</td>\n",
       "      <td>Five O'clock Vodka</td>\n",
       "      <td>1750</td>\n",
       "      <td>$7.20</td>\n",
       "      <td>$10.80</td>\n",
       "      <td>12</td>\n",
       "      <td>$129.60</td>\n",
       "      <td>21.00</td>\n",
       "      <td>5.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Store Number         City Zip Code  County Number      County  \\\n",
       "0 2015-11-04          3717       SUMNER    50674           9.00      Bremer   \n",
       "1 2016-03-02          2614    DAVENPORT    52807          82.00       Scott   \n",
       "2 2016-02-11          2106  CEDAR FALLS    50613           7.00  Black Hawk   \n",
       "3 2016-02-03          2501         AMES    50010          85.00       Story   \n",
       "4 2015-08-18          3654      BELMOND    50421          99.00      Wright   \n",
       "\n",
       "    Category              Category Name  Vendor Number  Item Number  \\\n",
       "0 1051100.00           APRICOT BRANDIES             55        54436   \n",
       "1 1011100.00           BLENDED WHISKIES            395        27605   \n",
       "2 1011200.00  STRAIGHT BOURBON WHISKIES             65        19067   \n",
       "3 1071100.00         AMERICAN COCKTAILS            395        59154   \n",
       "4 1031080.00             VODKA 80 PROOF            297        35918   \n",
       "\n",
       "            Item Description  Bottle Volume (ml) State Bottle Cost  \\\n",
       "0  Mr. Boston Apricot Brandy                 750             $4.50   \n",
       "1                    Tin Cup                 750            $13.75   \n",
       "2                   Jim Beam                1000            $12.59   \n",
       "3    1800 Ultimate Margarita                1750             $9.50   \n",
       "4         Five O'clock Vodka                1750             $7.20   \n",
       "\n",
       "  State Bottle Retail  Bottles Sold Sale (Dollars)  Volume Sold (Liters)  \\\n",
       "0               $6.75            12         $81.00                  9.00   \n",
       "1              $20.63             2         $41.26                  1.50   \n",
       "2              $18.89            24        $453.36                 24.00   \n",
       "3              $14.25             6         $85.50                 10.50   \n",
       "4              $10.80            12        $129.60                 21.00   \n",
       "\n",
       "   Volume Sold (Gallons)  \n",
       "0                   2.38  \n",
       "1                   0.40  \n",
       "2                   6.34  \n",
       "3                   2.77  \n",
       "4                   5.55  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To facilitate using a bigger file later, we'll keep just the columns that are available in this dataset\n",
    "all_columns = df.columns.values.tolist()\n",
    "df = df.copy()[all_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure accuracy, we are importing a list of Iowa zip codes, cities, counties and county numbers for the purposes of cleaning our data. We obtained our data from [here](http://www.unitedstateszipcodes.org/zip-code-database/), [here](http://www.iowayouthsurvey.iowa.gov/images/iacountiesnumbers.pdf) and [here](https://www.census.gov/geo/maps-data/data/tiger-line.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:37.742413",
     "start_time": "2016-10-12T09:49:37.696657"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>City</th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>County Number</th>\n",
       "      <th>Area (sqkm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50001</td>\n",
       "      <td>ACKWORTH</td>\n",
       "      <td>Warren</td>\n",
       "      <td>IA</td>\n",
       "      <td>91</td>\n",
       "      <td>62.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50002</td>\n",
       "      <td>ADAIR</td>\n",
       "      <td>Guthrie</td>\n",
       "      <td>IA</td>\n",
       "      <td>39</td>\n",
       "      <td>279.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50003</td>\n",
       "      <td>ADEL</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>IA</td>\n",
       "      <td>25</td>\n",
       "      <td>298.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50005</td>\n",
       "      <td>ALBION</td>\n",
       "      <td>Marshall</td>\n",
       "      <td>IA</td>\n",
       "      <td>64</td>\n",
       "      <td>69.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50006</td>\n",
       "      <td>ALDEN</td>\n",
       "      <td>Hardin</td>\n",
       "      <td>IA</td>\n",
       "      <td>42</td>\n",
       "      <td>317.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Zip Code      City    County State  County Number  Area (sqkm)\n",
       "0    50001  ACKWORTH    Warren    IA             91        62.80\n",
       "1    50002     ADAIR   Guthrie    IA             39       279.20\n",
       "2    50003      ADEL    Dallas    IA             25       298.09\n",
       "3    50005    ALBION  Marshall    IA             64        69.62\n",
       "4    50006     ALDEN    Hardin    IA             42       317.75"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in our location data file\n",
    "location_data = load_file('ia_zip_city_county_sqkm.csv')\n",
    "location_data = location_data.drop(location_data.columns[0], axis=1)\n",
    "location_data['Zip Code'] = location_data['Zip Code'].astype(str)\n",
    "location_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our hypothesis is that the demographics of an area affects the liquor sales. To test this, we brought in demographic data from [here](http://www.iowadatacenter.org/browse/ZCTAs.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:37.783252",
     "start_time": "2016-10-12T09:49:37.746743"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Check file path/ name\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'dropna'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fabbba4f112e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Remove any rows with null values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdemo_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dropna'"
     ]
    }
   ],
   "source": [
    "# Load in our demographic data file\n",
    "demo_data = load_file('IowaZIPdemos.csv')\n",
    "\n",
    "# Remove any rows with null values\n",
    "demo_data.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:37.955062",
     "start_time": "2016-10-12T09:49:37.787149"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All our data should be integers or floats\n",
    "# Create a list of column names if those columns are objects\n",
    "demo_cols = demo_data.columns.values.tolist()\n",
    "object_cols = [i for i in demo_cols if demo_data[i].dtype == 'O']\n",
    "\n",
    "# Define a function to remove symbols and convert numbers to floats\n",
    "def rem_symbols(x):\n",
    "    for i in [',', '%', '$', '-']:\n",
    "        x = x.replace(i, '')\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        print x\n",
    "\n",
    "# Convert all columns to floats\n",
    "for i in object_cols:\n",
    "    demo_data[i] = demo_data[i].map(rem_symbols)\n",
    "\n",
    "# Convert zips to strings for easy comparison\n",
    "demo_data['Area'] = demo_data['Area'].astype(str)\n",
    "demo_data['Area'] = demo_data['Area'].map(lambda x: x.strip('.0'))\n",
    "demo_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run a check on zip codes before joining the liquor sales data and the location data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:37.992784",
     "start_time": "2016-10-12T09:49:37.958308"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of unique zip codes in the liquor sales data\n",
    "liquor_zips = df['Zip Code'].drop_duplicates().tolist()\n",
    "\n",
    "# Create a list of unique zip codes as strings from the location data\n",
    "ref_zips = location_data['Zip Code'].tolist()\n",
    "\n",
    "# Create a list of zip codes that are present in the liquor sales data but not in the location data\n",
    "not_found = [x for x in liquor_zips if x not in ref_zips]\n",
    "print not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:38.453737",
     "start_time": "2016-10-12T09:49:37.995923"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each 'unknown' zip code, we obtain the corresponding city, county and county number in the liquor sales data\n",
    "# and return the same data for that city in our location data\n",
    "for i in not_found:\n",
    "    print df[['Zip Code', 'City', 'County', 'County Number']][df['Zip Code'] == i].drop_duplicates()\n",
    "    city = df['City'][df['Zip Code'] == i].drop_duplicates().iloc[0].upper()\n",
    "    print city\n",
    "    try:\n",
    "        print location_data[location_data['City']==city].drop_duplicates()\n",
    "    except:\n",
    "        print i, 'not in Iowa'\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above, we can kind of see what these zip codes are supposed to be.  \n",
    "Note: We will only be able to do this for a small dataset. As the dataset gets larger, more 'unknown' zips may appear and we may not be able to clean this manually.  \n",
    "\n",
    "Also note that the zip for Delaware, Delaware, Iowa is in fact correct. However, as it had a small population of 159 as at the 2010 census, we will not be considering it for the purposes of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:38.628125",
     "start_time": "2016-10-12T09:49:38.456655"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to map the correct zip codes to the incorrect ones\n",
    "# We will change 52036 to 0 so as to ignore it later on\n",
    "corrected_zips = {'52303': '52403',\\\n",
    "                  '712-2': '51529',\\\n",
    "                  '52087': '52057',\\\n",
    "                  '52084': '52804',\\\n",
    "                  '52036': '0',\\\n",
    "                  '52733': '52732',\\\n",
    "                  '56201': '52601',\\\n",
    "                  '50300': '50309'}\n",
    "\n",
    "for i in range(len(not_found)):\n",
    "    df.ix[df['Zip Code']==corrected_zips.keys()[i], 'Zip Code']=corrected_zips.values()[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:39.019524",
     "start_time": "2016-10-12T09:49:38.631223"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe to take the merged data\n",
    "df2 = df.copy()\n",
    "df2.drop(['County Number', 'City', 'County'], axis=1, inplace=True)\n",
    "df2 = df2.merge(location_data, how='left', on='Zip Code')\n",
    "df2.drop(['State'], axis=1, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:39.035865",
     "start_time": "2016-10-12T09:49:39.021881"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write a function that cross references related columns and fills the data in where it's missing\n",
    "def fill_missing(related_cols, column, dataframe):\n",
    "    related_cols.remove(column)\n",
    "    reference = dataframe[related_cols][dataframe[column].isnull()].drop_duplicates()\n",
    "    for j in range(len(related_cols)):\n",
    "        col_1 = reference[related_cols[j]]\n",
    "        for i in col_1:\n",
    "            try:\n",
    "                x = dataframe[column][(dataframe[related_cols[j]]==i) & (dataframe[column].notnull())].drop_duplicates()\n",
    "                if len(x) < 2:\n",
    "                    value = x.iloc[0]\n",
    "                    dataframe.ix[(dataframe[related_cols[j]]==i) & (dataframe[column].isnull()), column] = value\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:39.254549",
     "start_time": "2016-10-12T09:49:39.039045"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run our function to cross check category numbers and names\n",
    "fill_missing(['Category', 'Category Name'], 'Category Name', df2)\n",
    "fill_missing(['Category', 'Category Name'], 'Category', df2)\n",
    "\n",
    "# Run our function to cross check item numbers and names\n",
    "fill_missing(['Item Number', 'Item Description'], 'Item Description', df2)\n",
    "fill_missing(['Item Number', 'Item Description'], 'Item Number', df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:39.832592",
     "start_time": "2016-10-12T09:49:39.256749"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert all dollar columns to floats\n",
    "df2['State Bottle Cost'] = df2['State Bottle Cost'].map(lambda x: x.strip('$')).astype(float)\n",
    "df2['State Bottle Retail'] = df2['State Bottle Retail'].map(lambda x: x.strip('$')).astype(float)\n",
    "df2['Sale (Dollars)'] = df2['Sale (Dollars)'].map(lambda x: x.strip('$')).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T08:03:45.954603",
     "start_time": "2016-10-12T08:03:45.947919"
    }
   },
   "source": [
    "\n",
    "# Explore the data\n",
    "\n",
    "Perform some exploratory statistical analysis and make some plots, such as histograms of transaction totals, bottles sold, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:42.371786",
     "start_time": "2016-10-12T09:49:39.834595"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract Month and Year\n",
    "df2['Month'] = df2['Date'].map(lambda x: x.month)\n",
    "df2['Year'] = df2['Date'].map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:42.399256",
     "start_time": "2016-10-12T09:49:42.374349"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For the purposes of market research, we would want to look at full year data\n",
    "# Find all the non full years in the data set\n",
    "not_full_years = [i for i in df2['Year'].unique() if len(df2['Month'][df2['Year']==i].unique()) != 12]\n",
    "not_full_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:42.516049",
     "start_time": "2016-10-12T09:49:42.402193"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in not_full_years:\n",
    "    df2 = df2.drop(df2[df2['Year']==i].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:42.525678",
     "start_time": "2016-10-12T09:49:42.518785"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:43.803219",
     "start_time": "2016-10-12T09:49:42.529614"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the distribution of 'Bottles Sold', 'Sale (Dollars)', and 'Volume Sold (Liters)'\n",
    "# aggregated by store number\n",
    "hist_cols = ['Bottles Sold', 'Sale (Dollars)', 'Volume Sold (Liters)']\n",
    "for i in hist_cols:\n",
    "    sns.distplot(df2.groupby('Store Number')[i].sum());\n",
    "    plt.title(i);\n",
    "    plt.xlabel(i);\n",
    "    plt.ylabel('Frequency');\n",
    "    plt.xticks(rotation=45);\n",
    "    plt.show();\n",
    "    print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are outliers in all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:43.869778",
     "start_time": "2016-10-12T09:49:43.806396"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Taking a look at our top sales by zip code\n",
    "top_sales = df2.copy()\n",
    "top_sales.groupby('Zip Code')[['Sale (Dollars)', 'Volume Sold (Liters)']].\\\n",
    "sum().reset_index().sort_values(by='Sale (Dollars)', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:43.880381",
     "start_time": "2016-10-12T09:49:43.873472"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_histograms(data, col):\n",
    "    sns.distplot(data[col]);\n",
    "    plt.title(col);\n",
    "    plt.xlabel(col);\n",
    "    plt.ylabel('Frequency');\n",
    "    plt.xticks(rotation=45);\n",
    "    plt.show();\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:43.893553",
     "start_time": "2016-10-12T09:49:43.884258"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll take a look at our demographic data as well\n",
    "demo_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:45.157217",
     "start_time": "2016-10-12T09:49:43.897463"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll take a look at some of our demographic data as well\n",
    "demo_hist_cols = ['Per Capita Inc', 'Pop Below Poverty Level', '% P16+ in labor force']\n",
    "for i in demo_hist_cols:\n",
    "    draw_histograms(demo_data, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record your findings\n",
    "\n",
    "Be sure to write out anything observations from your exploratory analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of our market research, we are interested in total sales grouped by zip codes.  \n",
    "To get a fair idea of how each zip code does, we would want to remove the outlier stores (stores that do exceptionally well or poor) as these may not be a good indication of how an average store would fare in that zip code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine the data\n",
    "Now you are ready to compute the variables you will use for your regression from the data. For example, you may want to\n",
    "compute total sales per store from Jan to March of 2015, mean price per bottle, etc. Refer to the readme for more ideas appropriate to your scenario.\n",
    "\n",
    "Pandas is your friend for this task. Take a look at the operations [here](http://pandas.pydata.org/pandas-docs/stable/groupby.html) for ideas on how to make the best use of pandas and feel free to search for blog and Stack Overflow posts to help you group data by certain variables and compute sums, means, etc. You may find it useful to create a new data frame to house this summary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:45.168363",
     "start_time": "2016-10-12T09:49:45.160553"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:45.195719",
     "start_time": "2016-10-12T09:49:45.172433"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggregate sales and volume by stores\n",
    "agg_columns = ['Sale (Dollars)', 'Volume Sold (Liters)']\n",
    "store_summary = df2.groupby('Store Number')[agg_columns].sum().reset_index()\n",
    "store_summary.columns = ['Store Number', 'Store Sales', 'Store Volume']\n",
    "store_aggs = ['Store Sales', 'Store Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:46.318132",
     "start_time": "2016-10-12T09:49:45.199772"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in store_aggs:\n",
    "    draw_histograms(store_summary, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:46.329224",
     "start_time": "2016-10-12T09:49:46.321085"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In terms of total sales, we will remove the outliers\n",
    "# Set at total sales > 100000\n",
    "store_summary = store_summary[store_summary['Store Sales'] <= 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:47.389593",
     "start_time": "2016-10-12T09:49:46.334029"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in store_aggs:\n",
    "    draw_histograms(store_summary, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is still skewed but not as much as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:47.520972",
     "start_time": "2016-10-12T09:49:47.391680"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now merge the summary with our cleaned dataset \n",
    "columns_required = ['Year', 'Month', 'Store Number', 'Zip Code', 'Area (sqkm)']\n",
    "df3 = df2.copy()[columns_required].merge(store_summary, how='left', on='Store Number').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:47.548961",
     "start_time": "2016-10-12T09:49:47.523428"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:47.563841",
     "start_time": "2016-10-12T09:49:47.551278"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggregate sales and volume by zip code\n",
    "zip_summary = df3.groupby('Zip Code')[store_aggs].sum().reset_index().dropna()\n",
    "zip_summary.columns = ['Zip Code', 'Zip Sales', 'Zip Volume']\n",
    "zip_aggs = ['Zip Sales', 'Zip Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:48.452852",
     "start_time": "2016-10-12T09:49:47.566681"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in zip_aggs:\n",
    "    draw_histograms(zip_summary, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't be dropping outliers at the zip level because we want to see the zips that are doing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:48.502448",
     "start_time": "2016-10-12T09:49:48.455964"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df3[columns_required].merge(zip_summary, how='left', on='Zip Code').drop_duplicates()\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:48.546650",
     "start_time": "2016-10-12T09:49:48.505352"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a column for price per litre\n",
    "df3['Dollar per litre'] = df3['Zip Sales']/df3['Zip Volume']\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:48.602402",
     "start_time": "2016-10-12T09:49:48.550107"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add store count\n",
    "num_stores = df3[['Zip Code','Store Number']].drop_duplicates()\n",
    "num_stores = num_stores.groupby('Zip Code').count().reset_index()\n",
    "num_stores.columns = ['Zip Code', 'Store Count']\n",
    "df3 = df3.merge(num_stores, how='left', on='Zip Code')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:48.613428",
     "start_time": "2016-10-12T09:49:48.605674"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add stores per square kilometre\n",
    "df3['Stores per sqkm'] = df3['Store Count']/df3['Area (sqkm)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:48.683767",
     "start_time": "2016-10-12T09:49:48.618141"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scale the demo_data\n",
    "demo_data_scaled = demo_data.copy()\n",
    "cols_scale = demo_data_scaled.columns.values.tolist()[1:]\n",
    "scaler = StandardScaler().fit(demo_data_scaled[cols_scale])\n",
    "scaled_values = scaler.transform(demo_data_scaled[cols_scale])\n",
    "\n",
    "for i in range(len(cols_scale)):\n",
    "    demo_data_scaled[cols_scale[i]] = [x[i] for x in scaled_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:48.734996",
     "start_time": "2016-10-12T09:49:48.686964"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3_columns = df3.columns.values.tolist()\n",
    "df3_columns = df3_columns[2:]\n",
    "df3_columns.extend(['Month', 'Year'])\n",
    "df3 = df3[df3_columns]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:48.772780",
     "start_time": "2016-10-12T09:49:48.738107"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_df = df3.merge(demo_data_scaled, how='left', left_on='Zip Code', right_on='Area').drop('Area', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:48.853788",
     "start_time": "2016-10-12T09:49:48.776080"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refine the data\n",
    "Look for any statistical relationships, correlations, or other relevant properties of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:49.943710",
     "start_time": "2016-10-12T09:49:48.858973"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,10));\n",
    "sns.heatmap(model_df.corr()[['Zip Sales']].iloc[8:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:50.873914",
     "start_time": "2016-10-12T09:49:49.946294"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,10));\n",
    "sns.heatmap(model_df.corr()[['Dollar per litre']].iloc[8:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your models\n",
    "\n",
    "Using scikit-learn or statsmodels, build the necessary models for your scenario. Evaluate model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:50.883094",
     "start_time": "2016-10-12T09:49:50.876999"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = model_df.columns.values.tolist()\n",
    "print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:50.894711",
     "start_time": "2016-10-12T09:49:50.888153"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_features = ['Store Number', 'Zip Code', 'Area (sqkm)',\\\n",
    "                 'Zip Sales', 'Zip Volume', 'Dollar per litre', 'Store Count', 'Stores per sqkm', 'Month']\n",
    "for i in drop_features:\n",
    "    features.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:50.938369",
     "start_time": "2016-10-12T09:49:50.897892"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_df.dropna(inplace=True)\n",
    "X = model_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:51.510994",
     "start_time": "2016-10-12T09:49:50.942022"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_sales = model_df['Zip Sales']\n",
    "ridge = linear_model.RidgeCV(cv=5)\n",
    "model_sales = ridge.fit(X,y_sales)\n",
    "print 'r-squared: {}'.format(model_sales.score(X,y_sales))\n",
    "print 'alpha applied: {}'.format(model_sales.alpha_)\n",
    "\n",
    "feature_imp = pd.DataFrame([features, model_sales.coef_.tolist()], index=['feature', 'coef']).T\n",
    "feature_imp['coef'] = feature_imp['coef'].astype(float)\n",
    "feature_imp = feature_imp.sort_values(by='coef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:52.033039",
     "start_time": "2016-10-12T09:49:51.513910"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_dollar = model_df['Dollar per litre']\n",
    "ridge2 = linear_model.RidgeCV(cv=5)\n",
    "model_dollar = ridge2.fit(X,y_dollar)\n",
    "print 'r-squared: {}'.format(model_dollar.score(X,y_dollar))\n",
    "print 'alpha applied: {}'.format(model_dollar.alpha_)\n",
    "\n",
    "feature_imp_d = pd.DataFrame([features, model_dollar.coef_.tolist()], index=['feature', 'coef']).T\n",
    "feature_imp_d['coef'] = feature_imp_d['coef'].astype(float)\n",
    "feature_imp_d = feature_imp_d.sort_values(by='coef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot your results\n",
    "\n",
    "Again make sure that you record any valuable information. For example, in the tax scenario, did you find the sales from the first three months of the year to be a good predictor of the total sales for the year? Plot the predictions versus the true values and discuss the successes and limitations of your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:52.599847",
     "start_time": "2016-10-12T09:49:52.036086"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_sales = model_sales.predict(X)\n",
    "fig, ax = plt.subplots(figsize=(8,8));\n",
    "plt.scatter(predicted_sales, y_sales);\n",
    "plt.plot([min(y_sales), max(y_sales)], [min(y_sales), max(y_sales)], '-');\n",
    "plt.title('Predicted and actual sales');\n",
    "plt.xlabel('Predicted sales');\n",
    "plt.ylabel('Actual sales');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:53.058605",
     "start_time": "2016-10-12T09:49:52.602578"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_dollar = model_dollar.predict(X)\n",
    "fig, ax = plt.subplots(figsize=(8,8));\n",
    "plt.scatter(predicted_dollar, y_dollar);\n",
    "plt.plot([min(y_dollar), max(y_dollar)], [min(y_dollar), max(y_dollar)], '-');\n",
    "plt.title('Predicted and actual dollar per litre');\n",
    "plt.xlabel('Predicted');\n",
    "plt.ylabel('Actual');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Present the Results\n",
    "\n",
    "Present your conclusions and results. If you have more than one interesting model feel free to include more than one along with a discussion. Use your work in this notebook to prepare your write-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:53.077338",
     "start_time": "2016-10-12T09:49:53.061487"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict sales for all zip codes\n",
    "predict_df = location_data.copy()\n",
    "predict_df['Year'] = 2016\n",
    "predict_df = predict_df.merge(demo_data_scaled, left_on='Zip Code', right_on='Area').drop('Area', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:53.091167",
     "start_time": "2016-10-12T09:49:53.080836"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_predict = predict_df[features]\n",
    "all_sales = model_sales.predict(X_predict)\n",
    "all_dollar_per_litre = model_dollar.predict(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:53.193358",
     "start_time": "2016-10-12T09:49:53.095572"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_df['Predicted Total Sales'] = all_sales\n",
    "predict_df['Predicted Dollar/Litre'] = all_dollar_per_litre\n",
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:53.203088",
     "start_time": "2016-10-12T09:49:53.197755"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "present_columns = ['Zip Code', 'Predicted Total Sales', 'Predicted Dollar/Litre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:53.237704",
     "start_time": "2016-10-12T09:49:53.207078"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "present_df = predict_df[present_columns]\n",
    "present_df = present_df.merge(df3[['Zip Code', 'Store Count', 'Area (sqkm)', 'Stores per sqkm', 'Zip Sales']],\\\n",
    "                              how='left', on='Zip Code').drop_duplicates()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:51:50.284462",
     "start_time": "2016-10-12T09:51:50.110759"
    }
   },
   "source": [
    "predict_df.to_csv('predicted-numbers-with-features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-12T09:49:53.285764",
     "start_time": "2016-10-12T09:49:53.240450"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_10 = present_df.sort_values(by='Predicted Total Sales', ascending=False).head(10)\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
